{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "#import sys\n",
    "\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "#from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.metrics import r2_score\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir\n",
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")\n",
    "current_dir = os.getcwd()\n",
    "current_dir\n",
    "#set current working directory to H:\\VScode\\March Group\\March_Team_Project\\\n",
    "os.chdir(\"H:\\\\VScode\\\\March Group\\\\March_Team_Project\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "County Code            1.328799\n",
       "Site Num               1.411485\n",
       "NO2 Mean               1.002661\n",
       "O3 AQI                 2.162399\n",
       "SO2 Mean               2.693517\n",
       "SO2 1st Max Value      3.765834\n",
       "SO2 AQI                3.171309\n",
       "CO Mean                2.053753\n",
       "CO 1st Max Value       2.050279\n",
       "CO AQI                 1.972371\n",
       "AWND                   2.827331\n",
       "PGTM                   2.646656\n",
       "PRCP                   6.251311\n",
       "TAVG                   4.680941\n",
       "WDMV                  42.748820\n",
       "WT01                   4.058455\n",
       "WT02                  10.991683\n",
       "WT03                   6.138038\n",
       "WT04                  36.764360\n",
       "WT05                  33.888430\n",
       "WT06                  33.069562\n",
       "WT08                   6.261057\n",
       "WT09                  67.843202\n",
       "WT11                  36.764360\n",
       "WT13                   7.151200\n",
       "WT16                   8.278349\n",
       "WT18                  14.044666\n",
       "WT22                  21.950226\n",
       "O3_AQI_Group           4.031989\n",
       "SO2_AQI_Group         10.665846\n",
       "CO_AQI_Group         107.290493\n",
       "NO2_AQI_Group          3.531644\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load Outputs/DashBoardData.zip'\n",
    "merged_data = pd.read_csv(\"Outputs/DashBoardData.zip\", compression='zip', low_memory=False)\n",
    "# produce list of numeric and bool columns\n",
    "numeric_columns = merged_data.select_dtypes(include=['float64', 'int64', 'bool']).columns\n",
    "# drop WS_Latitude, WS_Longitude from numeric_columns\n",
    "numeric_columns = numeric_columns.drop(['WS_Latitude', 'WS_Longitude'])\n",
    "# create a list of columns with skewness greater than 1\n",
    "skewness = merged_data[numeric_columns].skew()\n",
    "skewness = skewness[skewness > 1]\n",
    "skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform data to standardise data ranges and correct skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit learn to apply transformations to the data to standardise the data and correct skewness\n",
    "merged_data_corrected=merged_data.copy()\n",
    "# apply power transformer to columns with skewness greater than 1\n",
    "power_transformer = PowerTransformer()\n",
    "merged_data_corrected[skewness.index] = power_transformer.fit_transform(merged_data_corrected[skewness.index])\n",
    "\n",
    "# apply standard scaler to all numeric columns\n",
    "scaler = StandardScaler()\n",
    "merged_data_corrected[numeric_columns] = scaler.fit_transform(merged_data_corrected[numeric_columns])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Correlation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation matrices have different shapes\n",
      "The shape of the correlation matrix for the transformed data is (80, 80)\n",
      "The shape of the correlation matrix for the original data is (48, 48)\n",
      "The program will stop\n",
      "p-value: nan\n",
      "degrees of freedom: 8702\n",
      "t-statistic: nan\n",
      "critical value: 1.9602366340016277\n",
      "null hypothesis rejected: False\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Compare the correlation matrix before and after the transformations\n",
    "# create a new column transformer\n",
    "column_transformer = ColumnTransformer(transformers=[('power_transformer', PowerTransformer(), skewness.index), ('standard_scaler', StandardScaler(), numeric_columns)])\n",
    "\n",
    "# create a new pipeline\n",
    "pipeline = Pipeline(steps=[('column_transformer', column_transformer)])\n",
    "\n",
    "# fit and transform the pipeline\n",
    "merged_data_transformed = pipeline.fit_transform(merged_data_corrected)\n",
    "\n",
    "# convert transformed data to a dataframe\n",
    "merged_data_transformed_df = pd.DataFrame(merged_data_transformed)\n",
    "# perform correlation matrix on transformed data\n",
    "correlation_matrix_transformed_corr = merged_data_transformed_df.corr()\n",
    "correlation_matrix_transformed_corr = correlation_matrix_transformed_corr.round(2)\n",
    "\n",
    "# perform correlation matrix on original data\n",
    "correlation_matrix_original = merged_data[numeric_columns].copy().corr()\n",
    "correlation_matrix_original = correlation_matrix_original.round(2)\n",
    "\n",
    "# check that correlation_matrix_transformed_corr and correlation_matrix_original are the same shape\n",
    "if correlation_matrix_transformed_corr.shape != correlation_matrix_original.shape:\n",
    "    print('The correlation matrices have different shapes')\n",
    "    # print the shapes of the correlation matrices\n",
    "    print(f'The shape of the correlation matrix for the transformed data is {correlation_matrix_transformed_corr.shape}')\n",
    "    print(f'The shape of the correlation matrix for the original data is {correlation_matrix_original.shape}')\n",
    "    print('The program will stop')\n",
    "    # stop the program\n",
    "    exit()\n",
    "else:\n",
    "    print('The correlation matrices have the same shape')\n",
    "\n",
    "# performa a statistical test to determine if the correlation matrices are significantly different\n",
    "# calculate the difference between the two correlation matrices\n",
    "# Flatten the correlation matrices to 1D arrays\n",
    "original_corr_values = correlation_matrix_original.values.flatten()\n",
    "transformed_corr_values = correlation_matrix_transformed_corr.values.flatten()\n",
    "\n",
    "# Perform a t-test to compare the two correlation matrices\n",
    "t_statistic, p_value = ttest_ind(original_corr_values, transformed_corr_values)\n",
    "\n",
    "# Calculate degrees of freedom\n",
    "degrees_of_freedom = len(original_corr_values) + len(transformed_corr_values) - 2\n",
    "\n",
    "# Calculate the critical value for a 95% confidence level\n",
    "critical_value = t.ppf(0.975, degrees_of_freedom)\n",
    "\n",
    "# Determine if the null hypothesis is rejected\n",
    "null_hypothesis_rejected = abs(t_statistic) > critical_value\n",
    "# print the results\n",
    "print(f'p-value: {p_value}')\n",
    "print(f'degrees of freedom: {degrees_of_freedom}')\n",
    "print(f't-statistic: {t_statistic}')\n",
    "print(f'critical value: {critical_value}')\n",
    "print(f'null hypothesis rejected: {null_hypothesis_rejected}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression Model for NO2 AGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preform a linear regression on the data to predict the pollution level\n",
    "# create a list of numeric columns\n",
    "numeric_columns = merged_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "# drop WS_Latitude, WS_Longitude from numeric_columns\n",
    "numeric_columns = numeric_columns.drop(['WS_Latitude', 'WS_Longitude'])\n",
    "\n",
    "# split data into features and target\n",
    "X = merged_data[numeric_columns]\n",
    "y = merged_data['NO2 AQI']\n",
    "\n",
    "# split data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# create a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict the target using the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse\n",
    "\n",
    "# save the model\n",
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'Outputs/Linear_Regression_Model.pkl')\n",
    "\n",
    "mse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = joblib.load('Outputs/Linear_Regression_Model.pkl')\n",
    "\n",
    "# predict the target using the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse\n",
    "\n",
    "# create a dataframe of the coefficients\n",
    "coefficients = pd.DataFrame(model.coef_, index=numeric_columns, columns=['Coefficient'])\n",
    "coefficients\n",
    "\n",
    "# create a dataframe of the intercept\n",
    "intercept = pd.DataFrame([model.intercept_], index=['Intercept'], columns=['Value'])\n",
    "intercept\n",
    "\n",
    "# save the coefficients and intercept to csv\n",
    "coefficients.to_csv('Outputs/Coefficients.csv')\n",
    "intercept.to_csv('Outputs/Intercept.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
